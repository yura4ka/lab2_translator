{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "I45xQuvEAYEd",
    "outputId": "64dbab74-473f-47fc-d0be-d1201519202a"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1OcC4k82CMBE",
    "outputId": "954a1f5e-aa6b-4089-b567-e8ae78ba49f9"
   },
   "outputs": [],
   "source": [
    "!pip3 install torchtext==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "fpZRcsunA2js",
    "outputId": "777a67d5-b212-4fae-b6fa-86b2d2ffb9ae"
   },
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "C4qSXjlNBWTj",
    "outputId": "52a9ad32-403b-44b6-cad8-f2a991e52dda"
   },
   "outputs": [],
   "source": [
    "!pip3 install -U spacy\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download uk_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EERRpTusBmNV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torchtext.disable_torchtext_deprecation_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rRBsHIkuBpws",
    "outputId": "210e4667-3747-497d-fc1c-7aa07491781c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>uk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let's try something.</td>\n",
       "      <td>Давайте щось спробуємо!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to go to sleep.</td>\n",
       "      <td>Маю піти спати.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Мюріел зараз двадцять.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>Пароль - \"Muiriel\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I will be back soon.</td>\n",
       "      <td>Я скоро повернуся.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           en                       uk\n",
       "0        Let's try something.  Давайте щось спробуємо!\n",
       "1      I have to go to sleep.          Маю піти спати.\n",
       "2          Muiriel is 20 now.   Мюріел зараз двадцять.\n",
       "3  The password is \"Muiriel\".      Пароль - \"Muiriel\".\n",
       "4        I will be back soon.       Я скоро повернуся."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC = \"en\"\n",
    "TGT = \"uk\"\n",
    "csv = pd.read_csv(\"../data/en-uk.tsv\", sep=\"\\t\", usecols=[1, 3], names=[SRC, TGT])\n",
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "35AM3L9SCH58"
   },
   "outputs": [],
   "source": [
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "uk_tokenizer = get_tokenizer(\"spacy\", language=\"uk_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONYvF0-DDEPU",
    "outputId": "987798e7-f679-43a8-d4df-079f546a3833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18523\n",
      "49759\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(data, tokenizer):\n",
    "    counter = Counter()\n",
    "    for d in data:\n",
    "        counter.update(tokenizer(d))\n",
    "    print(len(counter))\n",
    "    return vocab(\n",
    "        counter, specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"], special_first=True\n",
    "    )\n",
    "\n",
    "\n",
    "en_vocab = build_vocab(csv[SRC], en_tokenizer)\n",
    "uk_vocab = build_vocab(csv[TGT], uk_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK3U6E6XItWL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\yurii\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\yurii\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\yurii\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\yurii\\AppData\\Local\\Temp\\ipykernel_3608\\4253981761.py\", line 13, in <module>\n",
      "    data = data_process(csv)\n",
      "  File \"C:\\Users\\yurii\\AppData\\Local\\Temp\\ipykernel_3608\\4253981761.py\", line 6, in data_process\n",
      "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
      "C:\\Users\\yurii\\AppData\\Local\\Temp\\ipykernel_3608\\4253981761.py:6: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n"
     ]
    }
   ],
   "source": [
    "def data_process(csv):\n",
    "    raw_en_iter = iter(csv[SRC])\n",
    "    raw_uk_iter = iter(csv[TGT])\n",
    "    data = []\n",
    "    for raw_en, raw_uk in zip(raw_en_iter, raw_uk_iter):\n",
    "        en_tensor_ = torch.tensor(\n",
    "            [en_vocab[token] for token in en_tokenizer(raw_en)], dtype=torch.long\n",
    "        )\n",
    "        uk_tensor_ = torch.tensor(\n",
    "            [uk_vocab[token] for token in uk_tokenizer(raw_uk)], dtype=torch.long\n",
    "        )\n",
    "        data.append((en_tensor_, uk_tensor_))\n",
    "    return data\n",
    "\n",
    "\n",
    "data = data_process(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-xvppMILrWD",
    "outputId": "44f6d9fb-e751-4d85-f6b2-fd8345b9d8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_IDX = en_vocab[\"<pad>\"]\n",
    "BOS_IDX = en_vocab[\"<bos>\"]\n",
    "EOS_IDX = en_vocab[\"<eos>\"]\n",
    "print(PAD_IDX, uk_vocab[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYEiqJwsLxfj"
   },
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    en_batch, uk_batch = [], []\n",
    "    for en_item, uk_item in data_batch:\n",
    "        en_batch.append(\n",
    "            torch.cat(\n",
    "                [torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0\n",
    "            )\n",
    "        )\n",
    "        uk_batch.append(\n",
    "            torch.cat(\n",
    "                [torch.tensor([BOS_IDX]), uk_item, torch.tensor([EOS_IDX])], dim=0\n",
    "            )\n",
    "        )\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    uk_batch = pad_sequence(uk_batch, padding_value=PAD_IDX)\n",
    "    return en_batch, uk_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUG1z1mFMk6y"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    data, [0.8, 0.1, 0.1]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-M3FnovNRyT",
    "outputId": "56cf45bf-b296-4d86-8c54-78759c9ffe9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683 171712\n",
      "Shape of en: torch.Size([29, 64]) torch.int64\n",
      "Shape of uk: torch.Size([27, 64]) torch.int64\n",
      "['<bos>', 'You', \"'ve\", 'got', 'to', 'wake', 'up', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'Тобі', 'потрібно', 'прокидатися', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(train_loader) * BATCH_SIZE)\n",
    "for en, uk in test_loader:\n",
    "    en_itos = en_vocab.get_itos()\n",
    "    uk_itos = uk_vocab.get_itos()\n",
    "    print(f\"Shape of en: {en.shape} {en.dtype}\")\n",
    "    print(f\"Shape of uk: {uk.shape} {uk.dtype}\")\n",
    "    print([en_itos[w] for w in en.T[0]])\n",
    "    print([uk_itos[w] for w in uk.T[0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzsi0GIWVBKa"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOmgc6GzlfwI"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        emb_size,\n",
    "        nhead,\n",
    "        ff_dim,\n",
    "        num_enc_layers,\n",
    "        num_dec_layers,\n",
    "        pad_idx,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, emb_size, padding_idx=pad_idx)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, emb_size, padding_idx=pad_idx)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_enc_layers,\n",
    "            num_decoder_layers=num_dec_layers,\n",
    "            dim_feedforward=ff_dim,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask):\n",
    "        src = self.positional_encoding(self.src_emb(src))\n",
    "        tgt = self.positional_encoding(self.tgt_emb(tgt))\n",
    "\n",
    "        output = self.transformer(\n",
    "            src,\n",
    "            tgt,\n",
    "            src_mask=src_mask,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "        )\n",
    "        return self.fc_out(output)\n",
    "\n",
    "    def create_masks(self, src, tgt):\n",
    "        src_seq_len, tgt_seq_len = src.size(0), tgt.size(0)\n",
    "        src_mask = torch.zeros((src_seq_len, src_seq_len), device=src.device).type(\n",
    "            torch.bool\n",
    "        )\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
    "\n",
    "        src_padding_mask = (src == self.pad_idx).transpose(0, 1)\n",
    "        tgt_padding_mask = (tgt == self.pad_idx).transpose(0, 1)\n",
    "        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "    def generate_square_subsequent_mask(self, size):\n",
    "        return torch.triu(torch.ones(size, size) * float(\"-inf\"), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQYp8X6rmtho",
    "outputId": "75a1d074-f215-4bef-cd40-5dd0603f6187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 18527 49763\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SRC_VOCAB_SIZE = len(en_vocab)\n",
    "TGT_VOCAB_SIZE = len(uk_vocab)\n",
    "EMB_SIZE = 192\n",
    "NHEAD = 6\n",
    "FFN_HID_DIM = 192\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "print(DEVICE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVbT4TODmA5D",
    "outputId": "27d6fcfa-1e6d-46b1-a34e-2644673e6f44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    src_vocab_size=SRC_VOCAB_SIZE,\n",
    "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
    "    emb_size=EMB_SIZE,\n",
    "    nhead=NHEAD,\n",
    "    ff_dim=FFN_HID_DIM,\n",
    "    num_enc_layers=NUM_ENCODER_LAYERS,\n",
    "    num_dec_layers=NUM_DECODER_LAYERS,\n",
    "    pad_idx=PAD_IDX,\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_YC2mxi8rEh5",
    "outputId": "d2db8188-734f-403b-c561-1bc21a7a51d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 24,501,155 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "83eTC7ydoCd5"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, total=len(train_loader)):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        tgt_output = tgt[1:, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = model.create_masks(\n",
    "            src, tgt_input\n",
    "        )\n",
    "        logits = model(\n",
    "            src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), tgt_output.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, valid_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(valid_loader, total=len(valid_loader)):\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            tgt_input = tgt[:-1, :]\n",
    "            tgt_output = tgt[1:, :]\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = model.create_masks(\n",
    "                src, tgt_input\n",
    "            )\n",
    "            logits = model(\n",
    "                src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "            )\n",
    "\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), tgt_output.view(-1))\n",
    "            total_loss += float(loss)\n",
    "    return total_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6M-6ewa2s40w"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time: int, end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuOeey5-qLVQ",
    "outputId": "3ef7372e-6699-4708-d802-82b5388293a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2683 [00:00<?, ?it/s]d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "d:\\uni\\lyng\\lab2\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|██████████| 2683/2683 [13:10<00:00,  3.40it/s]\n",
      "100%|██████████| 336/336 [00:15<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 13m 26s\n",
      "\tTrain Loss: 3.660 | Train PPL:  38.855\n",
      "\t Val. Loss: 2.641 |  Val. PPL:  14.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [19:45<00:00,  2.26it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 19m 58s\n",
      "\tTrain Loss: 2.336 | Train PPL:  10.343\n",
      "\t Val. Loss: 2.052 |  Val. PPL:   7.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [19:10<00:00,  2.33it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 19m 23s\n",
      "\tTrain Loss: 1.802 | Train PPL:   6.061\n",
      "\t Val. Loss: 1.853 |  Val. PPL:   6.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [19:08<00:00,  2.34it/s]\n",
      "100%|██████████| 336/336 [00:15<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 19m 23s\n",
      "\tTrain Loss: 1.502 | Train PPL:   4.491\n",
      "\t Val. Loss: 1.758 |  Val. PPL:   5.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [19:13<00:00,  2.33it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 19m 27s\n",
      "\tTrain Loss: 1.310 | Train PPL:   3.705\n",
      "\t Val. Loss: 1.713 |  Val. PPL:   5.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [18:50<00:00,  2.37it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 19m 3s\n",
      "\tTrain Loss: 1.169 | Train PPL:   3.219\n",
      "\t Val. Loss: 1.692 |  Val. PPL:   5.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [18:54<00:00,  2.36it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 19m 7s\n",
      "\tTrain Loss: 1.070 | Train PPL:   2.914\n",
      "\t Val. Loss: 1.666 |  Val. PPL:   5.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [18:56<00:00,  2.36it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 19m 9s\n",
      "\tTrain Loss: 0.993 | Train PPL:   2.699\n",
      "\t Val. Loss: 1.643 |  Val. PPL:   5.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [19:04<00:00,  2.34it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 19m 17s\n",
      "\tTrain Loss: 0.934 | Train PPL:   2.544\n",
      "\t Val. Loss: 1.640 |  Val. PPL:   5.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [18:59<00:00,  2.36it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 19m 12s\n",
      "\tTrain Loss: 0.885 | Train PPL:   2.422\n",
      "\t Val. Loss: 1.620 |  Val. PPL:   5.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_loader)\n",
    "    valid_loss = evaluate(model, criterion, valid_loader)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../outputs/model.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
